# ğŸ¯ AutoJudge â€“ Problem Difficulty Predictor

AutoJudge is an end-to-end machine learning application that predicts the **difficulty level of programming problems** based on their textual content.  
The system analyzes problem titles and descriptions using NLP techniques and outputs a difficulty classification through an interactive **Streamlit web app**.

This project demonstrates a complete ML workflow â€” from preprocessing and feature engineering to model selection and deployment.

---

## ğŸ“Œ Problem Statement

Online coding platforms host thousands of problems with varying difficulty levels.  
Manual difficulty tagging is subjective, inconsistent, and time-consuming.

**Goal:**  
To automatically predict the **difficulty level** of a problem using its **title and description**, ensuring consistency and scalability.

---

## ğŸ§  Approach Overview

The project follows a structured machine learning pipeline:

1. **Text preprocessing**
2. **Feature extraction (TF-IDF + engineered features)**
3. **Model training & evaluation**
4. **Best model selection**
5. **Deployment using Streamlit**

---

## ğŸ§¾ Input Features

The model takes the following inputs:

- **Problem Title** (text)
- **Problem Description** (text)

### Engineered Features
- TF-IDF vectors from title and description
- Text length and word-count based numerical features
- Combined sparse and dense features using `hstack`

---

## ğŸ› ï¸ Text Preprocessing

Text data is cleaned and normalized using:
- Lowercasing
- Regex-based cleaning
- Whitespace normalization
- Removal of unwanted characters

Preprocessing is **identical during training and inference** to avoid data leakage.

---

## âš™ï¸ Feature Engineering

- TF-IDF vectorization for:
  - Problem titles
  - Problem descriptions
- Numeric features:
  - Character count
  - Word count
- Final feature matrix created by combining:
  - Sparse TF-IDF features
  - Dense numerical features

---

## ğŸ¤– Models Trained

Multiple models were trained and evaluated, including:

- Logistic Regression (baseline)
- Tree-based models
- Gradient Boostingâ€“based models

Each model was evaluated using appropriate performance metrics, and the **best-performing model** was selected for deployment.

---

## ğŸ† Final Model

- Best model selected based on evaluation performance
- Model and vectorizers serialized using **pickle**
- Loaded safely during inference in the Streamlit app

---

## ğŸŒ Web Application (Streamlit)

The project includes an interactive **Streamlit web app** that:

- Accepts user input (title + description)
- Applies the same preprocessing and feature extraction
- Loads the trained model and vectorizers
- Outputs the predicted **difficulty level**

---

## ğŸ—‚ï¸ Project Structure

```text
AutoJudge/
â”‚
â”œâ”€â”€ app.py                  # Streamlit application
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ trained_model.pkl   # Final trained model
â”‚   â”œâ”€â”€ vectorizer.pkl      # TF-IDF vectorizers
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ model_training.ipynb
â”‚   â”œâ”€â”€ feature_engineering.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
